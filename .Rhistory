age_prop <- age_dist / sum(age_dist)
p_h <- mean(age_prop * hosp_table$rate)
sub <- df[countyFIPS == u_id[j]]
#dates <- (min(sub$date) + 12):max(sub$date)
dates <- min(sub$date):max(sub$date)
out <- list()
for(i in 1:length(dates)){
#get days where people might already be hospitalized
hosp <- sub[date >= dates[i] - (m_i - t1) & date <= dates[i] - (t2 - t1)]
num_early <- round(sum(hosp$delta) * (1-p_h))
#get days where people won't be hospitalized yet
tmp <- sub[date > dates[i] - (t2 - t1) & date <= dates[i]]
num_late <- sum(tmp$delta)
walking <- (num_early + num_late) * under
walking_per_cap <- walking / sub$pop[1]
out[[i]] <- walking_per_cap * 100
}
probs <- unlist(out)
probs[1:12] <- NA
sub[, infect_prob := probs]
final[[j]] <- sub
setTxtProgressBar(pb, j)
}
df <- rbindlist(final)
df <- df[order(date)]
#---moving averages
df <- df[order(countyFIPS, date)]
df <- df[, r_t_three := frollmean(r_t, n = 3), by = countyFIPS]
df <- df[, r_t_seven := frollmean(r_t, n = 7), by = countyFIPS]
final <- list()
u_id <- unique(df$countyFIPS)
pb <- txtProgressBar(max = length(u_id), style = 3)
for(j in 1:length(u_id)){
sub <- df[countyFIPS == u_id[j]]
sub <- sub[order(-date)]
out <- list()
for(i in 1:length(sub$case_count)){
half <- sub$case_count[i]/2
index <- which(sub$case_count < half)[1]
out[[i]] <- as.numeric(sub$date[index] - sub$date[i]) * -1
}
sub[, doubling := unlist(out)]
final[[j]] <- sub
setTxtProgressBar(pb, j)
}
df <- rbindlist(final)
df <- df[order(date)]
df[, date := as.character(date)]
dbWriteTable(covid_db, 'counties', df, overwrite = TRUE)
print(paste0('Successful update at: ', Sys.time()))
update_history <- read.csv('~/working/cov_api/update_history.csv', stringsAsFactors = FALSE)
update_history <- rbind(update_history, data.frame(date = as.character(Sys.time())))
write.csv(update_history, '~/working/cov_api/update_history.csv', row.names = FALSE)
source('~/working/bigmap_api/create_files.R')
}
knitr::opts_chunk$set(echo = TRUE)
alpha <- 0.05
mat <- matrix(c(6,14,8,9,11,4,8,17,6), byrow = TRUE)
colnames(mat) <- c('0-1999','2000-5999','6000-11999')
mat
mat <- matrix(c(6,14,8,9,11,4,8,17,6), nrow = 3, byrow = TRUE)
colnames(mat) <- c('0-1999','2000-5999','6000-11999')
rownames(mat) <- c('0-1999','2000-5999','6000-11999')
colnames(mat) <- c('left','normal','right')
mat
qchisq(0.05, df = (2*2))
knitr::opts_chunk$set(echo = TRUE)
chi_alpha <- qchisq(alpha, df=(3-1)*(3-1), lower.tail = FALSE)
chi_alpha
alpha
chi_alpha <- qchisq(alpha, df=(3-1)*(3-1), lower.tail = FALSE)
chi_alpha
qchisq(0.05, df = (2*2), lower.tail = FALSE)
chisq.test(mat)
knitr::opts_chunk$set(echo = TRUE)
alpha <- 0.05
data <- matrix(c(6,14,8,9,11,4,8,17,6),
ncol = 3,
byrow = TRUE,
dimnames = list(c('Range_0_to_1999',
'Range_2000_to_5999',
'Range_6000_to_11999'),
c('Deflect_Left',
'Deflect_Normal',
'Deflect_Right')
)
)
knitr::kable(data)
chi_alpha <- qchisq(alpha, df=(3-1)*(3-1), lower.tail = FALSE)
chi_alpha
chi_0 <- chisq.test(data, correct = FALSE)
chi_0$statistic
2.4577 > 9.487729
pchisq(2.4577, 4, lower.tail = FALSE)
pvalue <- pchisq(as.numeric(chi_0$statistic),df=4, lower.tail = FALSE)
pvalue
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
# input our given data
number_As <- c(0:4)
observed_frequency <- c(4, 21, 10, 13, 2)
df <- data.frame(number_As, observed_frequency)
# print the table of given data
rmarkdown::paged_table(df)
# plot the data to get a sense of the problem information
ggplot() +
geom_col(mapping = aes(x = number_As, y = observed_frequency)) +
labs(title = "Bar Plot for Exercise 9.7.1",
x = "Number of A's Earned",
y = "Number of Students in Each Category") +
ggthemes::theme_clean()
N <- 50
alpha <- 0.05
k <- 5
# binomial parameters
n <- 6
prob <- 0.25
N * dbinom(x=0:4, size = 6, prob = 0.25)
# update the value of k
k <- 4
# create an empty vector for our expected frequencies
expected_frequency <- vector(length = k)
# calculate the expected number of A's for the first three bins (counts in each "bin")
expected_frequency[1:3] <- N * dbinom(x = c(0:2), size = n, prob = prob)
# remember we needed to combine the 4th and 5th bins expected counts (which are 3 and 4 A's respectively)
expected_frequency[4] <- N * sum(dbinom(x = c(3:4), size = n, prob = prob))
expected_frequency
# update the given observed data to combine the last two bins (counts of 3 A's and 4 A's)
number_As <- c(0:3)
observed_frequency <- c(4, 21, 10, 15)
df <- data.frame(number_As, observed_frequency)
chi_crit <- qchisq(p=alpha, df=4-0-1, lower.tail = FALSE)
chi_crit
# vectorized implementation of the test statistic in two steps:
# 1. calculate the numerator for each "bin"
df$numerator <- (df$observed_frequency-expected_frequency)^2
# 2. divide the numerator by the denominator (just the expected frequencies)
chi_0 <- sum(df$numerator/expected_frequency)
chi_0
chi_0 > chi_crit
pchisq(chi_0, df=3, lower.tail = FALSE)
#breakout groupeR
d <- data.frame(name = c('Foran','Eckland','Davis','Shiffler','Cox','Wetzel','Ondrejcek','Grubb','Doody','Norris','Bordes','Orr','Altrogge','Greenfield'),
team = c(rep(1,4), rep(2,4), rep(3,3), rep(4,3))
)
d$team <- d$team[sample(1:nrow(d), nrow(d))]
d <- d[order(d$team),]
d$driver <- 'No'
for(i in 1:length(unique(d$team))){
len <- nrow(d[d$team == unique(d$team)[i],])
d$driver[d$team == unique(d$team)[i]][sample(1:len, 1)] <- 'Yes'
}
d
36.5/50
32.5/50
#---improved munge script for covid data
suppressWarnings({
suppressMessages({
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
})
})
setwd('~/working/cov_api/')
#functions used
rt.func.v2<-function(dat,mean.Weibull=4.8,sd.Weibull=2.3){
r.vals<-numeric(length = (length(dat) - 2))
#get the Weibull parameters from mixdist's weibullpar function
mGT.params<-weibullpar(mean.Weibull, sd.Weibull, loc = 0)
alpha<-mGT.params[2] # called shape in weibullpar, alpha in a discrete Weilbull
beta<-mGT.params[1] # called scale in weibullpar, beta in a discrete Weibull
#the extraDistr package uses an altrnative parameterization of the Weibull (q, beta) from
#Nakagawa and Osaki (1975) where q = exp(-alpha^-beta), so...
q<-exp(-as.numeric(alpha)^(-as.numeric(beta)))
#Discretize Weibull via the extraDistr package's ddweibull function
w<- ddweibull(0:1000, as.numeric(q), as.numeric(beta), log = FALSE)
growth<-diff(dat)
growth<-pmax(growth, 0) # eliminate any erroneous downward shifts in the cumulative counts
#Estimate R(t) from equation (33) of Nishiura and Chowell (2009)
for(k in 2:length(growth)){
r.vals[k-1]<-growth[k]/(sum(growth[1:k]*rev(w[1:k])))
}
#Output the results
return(c(NA, NA, r.vals))
}
covid_db <- dbConnect(RSQLite::SQLite(), 'data/covid_db.sqlite')
#---check if need to update
suppressWarnings({
suppressMessages({
x <- tbl(covid_db, 'counties') %>%
filter(date == max(date, na.rm = TRUE)) %>%
select(date) %>%
collect()
})
})
db_date <- as.Date(x[1][[1]][1])
main <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv', colClasses = 'character', showProgress = FALSE)
main <- main[countyFIPS != '0']
keep_cols <- grep('V',colnames(main), invert = TRUE)
main <- main[, keep_cols, with=FALSE]
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
#if newer date in usafacts than db
if(db_date != facts_date){
#---finish cleaning up the usafacts data
main[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', main[nchar(countyFIPS) == 4, countyFIPS])
df <- melt.data.table(main, id.vars = 1:4, measure.vars = 5:ncol(main), variable.name = 'date', value.name = 'case_count')
df[, date := as.Date(as.character(date), format = '%m/%d/%y')][
, case_count := as.integer(gsub(',', '', case_count))
]
#add daily growth
df[, delta := lapply(.SD, function(d) d - shift(d)), by = countyFIPS, .SDcols = 'case_count']
#add percent increase
df[, per_delta := lapply(.SD, function(d) (d - shift(d))/shift(d)), by = countyFIPS, .SDcols = 'case_count']
df[is.nan(per_delta), 'per_delta'] <- NA
df[is.infinite(per_delta), 'per_delta'] <- NA
#add rt
df[, r_t := rt.func.v2(case_count), by = 'countyFIPS']
#brind in deaths
deaths <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv',
colClasses = 'character', showProgress = FALSE)
#drop bad data
d <- deaths[duplicated(deaths) == FALSE]
d <- d[countyFIPS != '0']
keep_cols <- grep('V',colnames(d), invert = TRUE)
d <- d[, keep_cols, with=FALSE]
#fix fips codes with leading 0
d[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', d[nchar(countyFIPS) == 4, countyFIPS])
d <- melt.data.table(d, id.vars = 1:4, measure.vars = 5:ncol(d), variable.name = 'date', value.name = 'deaths')
d[, date := as.Date(as.character(date), format = '%m/%d/%y')][
, deaths := as.integer(gsub(',', '', deaths))
]
d <- d[, c('countyFIPS', 'date', 'deaths')]
setkeyv(d, c('countyFIPS', 'date'))
setkeyv(df, c('countyFIPS', 'date'))
#merge deaths
df <- d[df]
#--add pops
pop <- fread('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv',
colClasses = 'character', showProgress = FALSE)
pop[, countyFIPS := paste0(STATE, COUNTY)]
pop <- pop[, c('countyFIPS', 'POPESTIMATE2019')]
pop[, pop := as.numeric(POPESTIMATE2019)]
pop <- pop[, c('countyFIPS', 'pop')]
setkey(pop, countyFIPS)
setkey(df, countyFIPS)
df <- pop[df]
#---per capita cases and deaths
#df[, cases_per_10k := (case_count / pop) * 10000]
#df[, deaths_per_10k := (deaths / pop) * 10000]
#---age pop
age_pop <- fread('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/asrh/cc-est2019-alldata.csv',
colClasses = 'character', showProgress = FALSE)
age_pop <- age_pop[YEAR == '12']
age_pop[, countyFIPS := paste0(STATE, COUNTY)]
age_pop[, AGEGRP := as.numeric(AGEGRP)]
#probability of hospitalization
#source: https://www.thelancet.com/action/showPdf?pii=S1473-3099%2820%2930243-7
hosp_table <- data.table(age = c('0-9','10-19','20-29','30-39','40-49','50-59','60-69','70-79','80+'),
rate = c(0, .000408, .0104, .0343, .0425, .0816, .118, .166, .184))
#---assumptions
#time from symptoms to test result
t1 <- 2
#time from symptoms to hospitalization
#source: https://jamanetwork.com/journals/jama/fullarticle/2761044
t2 <- 7
#max time infectious
m_i <- 10
#under-reporting
under <- 10
final <- list()
u_id <- unique(df$countyFIPS)
pb <- txtProgressBar(max = length(u_id), style = 3)
for(j in 1:length(u_id)){
ages <- age_pop[countyFIPS == u_id[j]]
age_dist <- c(sum(as.numeric(ages[AGEGRP %in% c(1,2), TOT_POP])), sum(as.numeric(ages[AGEGRP %in% c(3,4), TOT_POP])), sum(as.numeric(ages[AGEGRP %in% c(5,6), TOT_POP])),
sum(as.numeric(ages[AGEGRP %in% c(7,8), TOT_POP])), sum(as.numeric(ages[AGEGRP %in% c(9,10), TOT_POP])), sum(as.numeric(ages[AGEGRP %in% c(11,12), TOT_POP])),
sum(as.numeric(ages[AGEGRP %in% c(13,14), TOT_POP])), sum(as.numeric(ages[AGEGRP %in% c(15,16), TOT_POP])), sum(as.numeric(ages[AGEGRP %in% c(17,18), TOT_POP])))
age_prop <- age_dist / sum(age_dist)
p_h <- mean(age_prop * hosp_table$rate)
sub <- df[countyFIPS == u_id[j]]
#dates <- (min(sub$date) + 12):max(sub$date)
dates <- min(sub$date):max(sub$date)
out <- list()
for(i in 1:length(dates)){
#get days where people might already be hospitalized
hosp <- sub[date >= dates[i] - (m_i - t1) & date <= dates[i] - (t2 - t1)]
num_early <- round(sum(hosp$delta) * (1-p_h))
#get days where people won't be hospitalized yet
tmp <- sub[date > dates[i] - (t2 - t1) & date <= dates[i]]
num_late <- sum(tmp$delta)
walking <- (num_early + num_late) * under
walking_per_cap <- walking / sub$pop[1]
out[[i]] <- walking_per_cap * 100
}
probs <- unlist(out)
probs[1:12] <- NA
sub[, infect_prob := probs]
final[[j]] <- sub
setTxtProgressBar(pb, j)
}
df <- rbindlist(final)
df <- df[order(date)]
#---moving averages
df <- df[order(countyFIPS, date)]
df <- df[, r_t_three := frollmean(r_t, n = 3), by = countyFIPS]
df <- df[, r_t_seven := frollmean(r_t, n = 7), by = countyFIPS]
final <- list()
u_id <- unique(df$countyFIPS)
pb <- txtProgressBar(max = length(u_id), style = 3)
for(j in 1:length(u_id)){
sub <- df[countyFIPS == u_id[j]]
sub <- sub[order(-date)]
out <- list()
for(i in 1:length(sub$case_count)){
half <- sub$case_count[i]/2
index <- which(sub$case_count < half)[1]
out[[i]] <- as.numeric(sub$date[index] - sub$date[i]) * -1
}
sub[, doubling := unlist(out)]
final[[j]] <- sub
setTxtProgressBar(pb, j)
}
df <- rbindlist(final)
df <- df[order(date)]
df[, date := as.character(date)]
dbWriteTable(covid_db, 'counties', df, overwrite = TRUE)
print(paste0('Successful update at: ', Sys.time()))
update_history <- read.csv('~/working/cov_api/update_history.csv', stringsAsFactors = FALSE)
update_history <- rbind(update_history, data.frame(date = as.character(Sys.time())))
write.csv(update_history, '~/working/cov_api/update_history.csv', row.names = FALSE)
source('~/working/bigmap_api/create_files.R')
}
faceoff.circle = function (x,y, thiscol="red") {
theta = seq(0,2*pi,length=300)
#outer.
polygon (x + 15*cos(theta),
y + 15*sin(theta),
lwd=2,
border=thiscol)
polygon (x + 1*cos(theta),
y + 1*sin(theta),
col=thiscol,
border=thiscol)
segments (c(x-0.75,x-0.75, x+0.75,x+0.75, x-0.75,x-0.75, x+0.75,x+0.75),
c(y-2,y-2, y-2,y-2, y+2,y+2,y+2,y+2),
c(x-0.75,x-3.75, x+0.75,x+3.75, x-0.75,x-3.75, x+0.75,x+3.75),
c(y-6,y-2, y-6,y-2, y+6,y+2,y+6,y+2),
col=thiscol, lwd=2)
dd <- (5+7/12)/2
segments (c(x-15, x-15, x+15, x+15),
c(y-dd, y+dd, y-dd, y+dd),
c(x-17, x-17, x+17, x+17),
c(y-dd, y+dd, y-dd, y+dd),
col=thiscol, lwd=2)
}
goal.crease = function (flip=1, fillcol="lightblue", thiscol="red") {
xseq = seq(-4,4,length=100)
polygon (c(-4, xseq, 4),
flip*c(89, 83+xseq^2/4^2*1.5, 89),
col=fillcol, border=thiscol)
}
rink.plot.blank = function (...) {
plot(c(42.6,-42.6), c(101,0), ty="n", ylim=c(101,25), xlim=c(-42.6, 42.6), ylab="", xlab="", axes=FALSE, ...)
}
rink.plot = function (fresh=TRUE, thiscol="red", ...) {
if (fresh) rink.plot.blank (...)
rect(-42.5, 25, 42.5, 26, col=4, border=4)
lines (c(-42.5,
-42.5 + 28 - 28*cos(seq(0,pi/2,length=20)),
42.5 - 28 + 28*cos(seq(pi/2,0,length=20)),
42.5),
c(15,
72 + 28*sin(seq(0,pi/2,length=20)),
72 + 28*sin(seq(pi/2,0,length=20)),
15),
col=1, lwd=2)
goal.line.extreme = 42.5 - 28 + sqrt(28^2 - (28-11)^2)
lines(goal.line.extreme*c(-1, 1), rep(89,2), col=thiscol, lwd=2)        #the goal line.
lines(c(-3,-3,3,3), c(90,92,92,90)-1, col=1, lwd=3)    #the goal net.
goal.crease(thiscol=thiscol)
segments(c(-11, 11), c(89,89), c(-14,14), c(100,100), col=thiscol, lwd=2)
faceoff.circle (-22, 69, thiscol)
faceoff.circle (22, 69, thiscol)
}
full.rink = function () {
theta = seq(0,2*pi,length=300)
par(mar=c(0,0,0,0))
plot(c(-42.6, 42.6), c(-101,101), ty="n", ylim=c(-101,101), xlim=c(-42.6, 42.6), ylab="", xlab="", axes=FALSE)
polygon (15*cos(theta), 15*sin(theta), lwd=2, border=4)
theta2 = seq (pi/2, 3*pi/2, length=300)
polygon (42.5 + 10*cos(theta2), 10*sin(theta2), lwd=2, border=2)
rect(-42.5, 25, 42.5, 26, col=4, border=4)
rect(-42.5, -25, 42.5, -26, col=4, border=4)
rect(-42.5, -0.5, 42.5, 0.5, col=2, border=2)
lines (c(-42.5,
-42.5 + 28 - 28*cos(seq(0,pi/2,length=20)),
42.5 - 28 + 28*cos(seq(pi/2,0,length=20)),
42.5),
c(15,
72 + 28*sin(seq(0,pi/2,length=20)),
72 + 28*sin(seq(pi/2,0,length=20)),
15),
col=1, lwd=2)
lines (c(-42.5,
-42.5 + 28 - 28*cos(seq(0,pi/2,length=20)),
42.5 - 28 + 28*cos(seq(pi/2,0,length=20)),
42.5),
c(15,
-72 - 28*sin(seq(0,pi/2,length=20)),
-72 - 28*sin(seq(pi/2,0,length=20)),
15),
col=1, lwd=2)
goal.line.extreme = 42.5 - 28 + sqrt(28^2 - (28-11)^2)
lines(goal.line.extreme*c(-1, 1), rep(89,2), col=2,lwd=2)        #the goal line.
lines(goal.line.extreme*c(-1, 1), rep(-89,2), col=2,lwd=2)        #the goal line.
lines(c(-3,-3,3,3), c(90,92,92,90)-1, col=1, lwd=3)    #the goal net.
lines(c(-3,-3,3,3), -(c(90,92,92,90)-1), col=1, lwd=3)    #the goal net.
goal.crease(); goal.crease(-1)
## traps.
segments(c(-11, 11, -11, 11), c(89,89,-89,-89),
c(-14,14,-14,14), c(100,100, -100,-100), col=2, lwd=2)
faceoff.circle (-22, 69)
faceoff.circle (22, 69)
faceoff.circle (-22, -69)
faceoff.circle (22, -69)
faceoff.dot = function (x,y) {
polygon (x + 1*cos(theta),
y + 1*sin(theta),
col=2,
border=2)
}
faceoff.dot (22,20); faceoff.dot (22,-20); faceoff.dot (-22,20); faceoff.dot (-22,-20);
}
#full.rink()
full.rink()
1+5+3+3+5+3
#make LE data
library(data.table)
dt <- data.table('~/Downloads/le_data.csv')
dt
dt <- data.table('~/Downloads/le_data (1).csv')
dt <- fread('~/Downloads/le_data.csv')
dt
dt <- dt[Year == 2014]
dt
1+1+1+5+3+3+3+3
library(rworldmap)
library(countrycode)
install.packages('countrycode')
countrycode::countrycode(dt$Country[1])
countrycode::countrycode(dt$Country[1], origin = 'country.name', destination = 'continent')
#add continents
dt[, continent := countrycode(Country, origin = 'country.name', destination = 'continent')]
library(countrycode)
#add continents
dt[, continent := countrycode(Country, origin = 'country.name', destination = 'continent')]
dt
dt[is.na(Population) == FALSE]
dt <- fread('~/Downloads/le_data.csv')
dt <- dt[Year == 2014]
dt <- dt[is.na(Population) == FALSE]
#add continents
dt[, continent := countrycode(Country, origin = 'country.name', destination = 'continent')]
is.na(dt$continent)
#add continents
dt[, Continent := countrycode(Country, origin = 'country.name', destination = 'continent')]
dt <- fread('~/Downloads/le_data.csv')
dt <- dt[Year == 2014]
dt <- dt[is.na(Population) == FALSE]
#add continents
dt[, Continent := countrycode(Country, origin = 'country.name', destination = 'continent')]
mod <- lm(`Life expectancy` ~ `Country`)
mod <- lm(`Life expectancy` ~ `Country`, dt)
mod <- lm(`Life expectancy` ~ `Continent`, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `status`, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `Status`, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `Status` + Continent, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `Status` + Continent + Population, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `Status` + Continent + GDP, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `Status` + Continent + GDP + Schooling, dt)
summary(mod)
mod <- lm(`Life expectancy` ~ `Status` + Continent + Schooling, dt)
summary(mod)
??vif
library(car)
vif(mod)
GGally::ggpairs(dt)
GGally::ggpairs(dt[, -c('Country')])
GGally::ggpairs(dt[, c('Continent','Schooling')])
GGally::ggpairs(dt[, c('GDP','Schooling')])
summary(mod)
vif(mod)
mod <- lm(`Life expectancy` ~ `Status` + Continent, dt)
summary(mod)
fwrite(dt, '~/Documents/courses/SE375/graded_events/who_data.csv')
110+80+10+5.5
110-80-10-5.5
shiny::runApp('~/working/chat_vis')
reticulate::repl_python()
