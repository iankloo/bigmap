ft$subject_name <- NA
for(i in 1:nrow(ft)){
ft$subject_name[i] <- p$first[p$id == ft$subject_name_id[i]]
}
ft
#---surveys
st <- exp_st
res <- exp_dt
st <- st[uuid %in% res$uuid]
st$exp <- NA
st$name <- NA
for(i in 1:nrow(st)){
st$exp[i] <- res$experiment_name[res$uuid == st$uuid[i]][1]
st$name[i] <- res$rater.first[res$uuid == st$uuid[i]][1]
}
st
View(st)
#---load cadets
library(data.table)
source('~/Documents/projects/Elo/interact_with_api.R')
df <- fread('~/Downloads/cft_roster_0722.csv')
#---load cadets
library(data.table)
source('~/Documents/projects/Elo/interact_with_api.R')
df <- fread('~/Downloads/cft_roster_0722.csv')
df
#make sure everyone is in the database
p <- get_people()
sub <- df[1]
sub
parse_name <- function(n){
num_space <- sum(unlist(strsplit(n, '')) == ' ')
if(num_space == 1){
last <- gsub('(.+) .+', '\\1', n)
first <- gsub('.+ (.+)', '\\1', n)
middle <- ''
} else if(num_space == 2){
last <- gsub('(.+) .+ .+', '\\1', n)
first <- gsub('.+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ (.+)', '\\1', n)
} else if(num_space == 3){
last <- gsub('(.+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ (.+)', '\\1', n)
} else if(num_space == 4){
last <- gsub('(.+ .+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ .+ (.+)', '\\1', n)
} else{
last <- first <- middle <- NA
}
return(data.table(first, middle, last))
}
out <- lapply(df$NAME, parse_name)
final <- rbindlist(out)
df <- cbind(df, final)
df
0 <- 1
i <- 1
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]
#make sure everyone is in the database
p <- data.table(get_people())
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]
df[i, first]
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]
df <- df[, c('first','middle','last','EMAIL')]
df$rank <- 'CDT'
colnames(df)[4] <- 'email'
df <- fread('~/Downloads/cft_roster_0722.csv')
parse_name <- function(n){
num_space <- sum(unlist(strsplit(n, '')) == ' ')
if(num_space == 1){
last <- gsub('(.+) .+', '\\1', n)
first <- gsub('.+ (.+)', '\\1', n)
middle <- ''
} else if(num_space == 2){
last <- gsub('(.+) .+ .+', '\\1', n)
first <- gsub('.+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ (.+)', '\\1', n)
} else if(num_space == 3){
last <- gsub('(.+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ (.+)', '\\1', n)
} else if(num_space == 4){
last <- gsub('(.+ .+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ .+ (.+)', '\\1', n)
} else{
last <- first <- middle <- NA
}
return(data.table(first, middle, last))
}
out <- lapply(df$NAME, parse_name)
final <- rbindlist(out)
df <- cbind(df, final)
df <- df[, c('first','middle','last','EMAIL')]
df$rank <- 'CDT'
colnames(df)[4] <- 'email'
df <- fread('~/Downloads/cft_roster_0722.csv')
parse_name <- function(n){
num_space <- sum(unlist(strsplit(n, '')) == ' ')
if(num_space == 1){
last <- gsub('(.+) .+', '\\1', n)
first <- gsub('.+ (.+)', '\\1', n)
middle <- ''
} else if(num_space == 2){
last <- gsub('(.+) .+ .+', '\\1', n)
first <- gsub('.+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ (.+)', '\\1', n)
} else if(num_space == 3){
last <- gsub('(.+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ (.+)', '\\1', n)
} else if(num_space == 4){
last <- gsub('(.+ .+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ .+ (.+)', '\\1', n)
} else{
last <- first <- middle <- NA
}
return(data.table(first, middle, last))
}
out <- lapply(df$NAME, parse_name)
final <- rbindlist(out)
df <- cbind(df, final)
df <- df[, c('first','middle','last','Email')]
df$rank <- 'CDT'
colnames(df)[4] <- 'email'
#make sure everyone is in the database
p <- data.table(get_people())
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]
i <- 1
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]
for(i in 1:nrow(df)){
if(nrow(p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]) == 0){
print(i)
}
}
i <- 1
nrow(p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]) == 0
View(p)
p_df <- df[i, -c('db_id', 'squadID')]
p_df <- df[i]
p_df
df <- fread('~/Downloads/cft_roster_0722.csv')
parse_name <- function(n){
num_space <- sum(unlist(strsplit(n, '')) == ' ')
if(num_space == 1){
last <- gsub('(.+) .+', '\\1', n)
first <- gsub('.+ (.+)', '\\1', n)
middle <- ''
} else if(num_space == 2){
last <- gsub('(.+) .+ .+', '\\1', n)
first <- gsub('.+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ (.+)', '\\1', n)
} else if(num_space == 3){
last <- gsub('(.+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ (.+)', '\\1', n)
} else if(num_space == 4){
last <- gsub('(.+ .+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ .+ (.+)', '\\1', n)
} else{
last <- first <- middle <- NA
}
return(data.table(first, middle, last))
}
out <- lapply(df$NAME, parse_name)
final <- rbindlist(out)
View(final)
df <- fread('~/Downloads/cft_roster_0722.csv')
parse_name <- function(n){
num_space <- sum(unlist(strsplit(n, '')) == ' ')
if(num_space == 1){
last <- gsub('(.+) .+', '\\1', n)
first <- gsub('.+ (.+)', '\\1', n)
middle <- ''
} else if(num_space == 2){
last <- gsub('(.+) .+ .+', '\\1', n)
first <- gsub('.+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ (.+)', '\\1', n)
} else if(num_space == 3){
last <- gsub('(.+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ (.+)', '\\1', n)
} else if(num_space == 4){
last <- gsub('(.+ .+ .+) .+ .+', '\\1', n)
first <- gsub('.+ .+ .+ (.+) .+', '\\1', n)
middle <- gsub('.+ .+ .+ .+ (.+)', '\\1', n)
} else{
last <- first <- middle <- NA
}
return(data.table(first, middle, last))
}
out <- lapply(df$NAME, parse_name)
final <- rbindlist(out)
df <- cbind(df, final)
df <- df[, c('first','middle','last','Email')]
df$rank <- 'CDT'
colnames(df)[4] <- 'email'
#make sure everyone is in the database
p <- data.table(get_people())
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]
for(i in 1:nrow(df)){
if(nrow(p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email]]) == 0){
p_df <- df[i]
add_people(p_df)
print(p_df)
}
}
df <- fread('~/Downloads/cft_roster_0722.csv')
out <- lapply(df$NAME, parse_name)
final <- rbindlist(out)
df <- cbind(df, final)
df[, squadID := paste0(SUMCO, SUMPLT, SUMSQD)]
df <- df[, c('first','middle','last','Email', 'squadID')]
df$rank <- 'CDT'
colnames(df)[4] <- 'email'
View(df)
table(df$squadID)
u_squad <- unique(df$squadID)
u_squad
i <- 1
sub <- df[squadID == u_squad[i]]
sub
ids <- as.numeric(sub[, db_id])
df$db_id <- ''
for(i in 1:nrow(df)){
df[i, 'db_id'] <- p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email], id]
}
i <- 1
df$db_id <- ''
p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email], id]
df[i, first]
middle == df[i, middle]
df[i, middle]
df[i, last]
df[i, email]
p <- data.table(get_people())
df$db_id <- ''
for(i in 1:nrow(df)){
df[i, 'db_id'] <- p[first == df[i, first] & middle == df[i, middle] & last == df[i, last] & email == df[i, email], id]
}
View(df)
u_squad <- unique(df$squadID)
i <- 1
sub <- df[squadID == u_squad[i]]
ids <- as.numeric(sub[, db_id])
ids
name <- paste0('CFT Initial Peer Ratings: ', u_squad[i])
name
#make sure you can load these, if not do install.packages('data.table') substituting the names of the other libraries you need
library(data.table)
library(httr)
library(jsonlite)
#-toggle cft/cldt by commenting one of them out
group <- 'CFT'
#---get results from DB
token <- '281ddaccf4f2d13593f26480a7a55f390dfb0fc0'
url_base <- 'https://appdseelo.azurewebsites.net/'
get_experiments <- function(){
url <- paste0(url_base, 'api/v1/exp_external/')
full_token <- paste0('Token ', token)
res <- GET(url, add_headers(Authorization = full_token))
if(res$status_code == 200){
results <- fromJSON(content(res, 'text', encoding = 'latin1'))
return(results)
} else{
stop(paste0('in API call. Status code: ', res$status_code))
}
}
get_results <- function(exp_id){
url <- paste0(url_base, '/api/v1/res_external/?exp_id=', exp_id)
full_token <- paste0('Token ', token)
res <- GET(url, add_headers(Authorization = full_token))
if(res$status_code == 200){
results <- fromJSON(content(res, 'text', encoding = 'latin1'))
return(results)
} else{
stop(paste0('in API call. Status code: ', res$status_code))
}
}
exp <- get_experiments()
exp <- data.table(exp)
exps <- exp[grep(group, exp$title)]
rater_cols <- c('rater.id', 'rater.first', 'rater.middle', 'rater.last', 'rater.email', 'uuid')
out <- list()
pb <- txtProgressBar(max = nrow(exps), style = 3)
for(i in 1:nrow(exps)){
ex_id <- exps[i, id]
r <- data.table(get_results(ex_id))
all <- r[, rater_cols, with = FALSE]
all <- unique(all)
all$complete <- ''
for(j in 1:nrow(all)){
s <- r[rater.id == all$rater.id[j]]
if(TRUE %in% is.na(s$end)){
all[j, 'complete'] <- 'no'
}else{
all[j, 'complete'] <- 'yes'
}
}
all[, squadID := gsub(paste0(group, ' Initial Peer Ratings: (.*)'), '\\1', exps$title[i])]
out[[i]] <- all
setTxtProgressBar(pb, i)
}
report <- rbindlist(out)
print(paste0(100 * round(sum(report$complete == 'yes') / nrow(report), 4), '% complete'))
fwrite(report, paste0(group, '_report.csv'))
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
setwd('~/working/bigmap')
covid_db <- dbConnect(RSQLite::SQLite(), '~/working/cov_api/data/covid_db.sqlite')
dates <- tbl(covid_db, 'counties') %>%
select(date) %>%
collect()
dates <- as.Date(unique(dates$date))
existing <- as.Date(substr(list.files('geojsons/'), start = 1, stop = 8), '%Y%m%d')
dates <- dates[which(!dates %in% existing)]
data <- tbl(covid_db, 'counties') %>%
collect()
data <- as.data.table(data)
county_shapes <- readRDS('~/working/cov_api/data/all_counties.RDS')
rn <- row.names(county_shapes@data)
county_shapes$STATE <- as.character(county_shapes$STATE)
county_shapes$COUNTY <- as.character(county_shapes$COUNTY)
county_shapes$FIPS <- paste0(county_shapes$STATE, county_shapes$COUNTY)
pb <- txtProgressBar(max = length(dates), style = 3)
for(l in 1:length(dates)){
dat <- data[date == dates[l], c('countyFIPS', 'date', 'case_count', 'per_delta', 'infect_prob', 'r_t', 'deaths', 'doubling', 'r_t_seven', 'r_t_three')]
# dat <- jsonlite::fromJSON(paste0('http://160.1.89.242/alldata?min_date=20200301&max_date=', gsub('-', '', Sys.Date() - 1)))
# dat <- data.table(dat)
dat[, r_t := round(r_t, 2)]
dat[, r_t_three := round(r_t_three, 2)]
dat[, r_t_seven := round(r_t_seven, 2)]
dat[, per_delta := round(per_delta* 100, 2) ]
dat[, infect_prob := round(infect_prob, 2) ]
# #---make wide timeseries data - every variable/date combo gets a column
# u_id <- unique(dat$countyFIPS)
# out <- list()
# for(i in 1:length(u_id)){
#   sub <- dat[countyFIPS == u_id[i]]
#   sub <- unique(sub, by=c("countyFIPS", "date"))
#
#   out_tmp <- list()
#   for(j in 1:nrow(sub)){
#     cols <- paste0(colnames(sub)[3:ncol(sub)],'_', gsub('-', '', sub$date[j]))
#     tmp <- data.frame(sub[j, 3:ncol(sub)])
#     colnames(tmp) <- cols
#     out_tmp[[j]] <- tmp
#   }
#   z <- cbind(sub[1, 1], do.call('cbind', out_tmp))
#   out[[i]] <- z
# }
#
# final <- rbindlist(out)
#merge into county shapes
county_shapes_out <- sp::merge(county_shapes, dat, by.x = 'FIPS', by.y = 'countyFIPS')
row.names(county_shapes_out) <- rn
county_shapes_out@data$CENSUSAREA <- NULL
county_shapes_out@data$LSAD <- NULL
county_shapes_out@data$COUNTY <- NULL
county_shapes_out@data$STATE <- NULL
county_shapes_out@data$GEO_ID <- NULL
filename <- paste0('~/working/bigmap/geojsons/', gsub('-', '', dates[l]), '.geojson')
geojsonio::geojson_write(county_shapes_out, file = filename)
setTxtProgressBar(pb, l)
}
#cache data for charts by area
area <- unique(data$countyFIPS)
dat <- data[date >= '2020-03-01']
for(i in 1:length(area)){
sub <- dat[countyFIPS == area[i]]
jsonlite::write_json(sub, path = paste0('chart_data/', area[i], '.json'))
}
filename <- paste0('~/working/bigmap_alt/geojsons/', gsub('-', '', dates[l]), '.geojson')
geojsonio::geojson_write(county_shapes_out, file = filename)
setwd('~/working/bigmap_alt')
#cache data for charts by area
area <- unique(data$countyFIPS)
dat <- data[date >= '2020-03-01']
for(i in 1:length(area)){
sub <- dat[countyFIPS == area[i]]
jsonlite::write_json(sub, path = paste0('chart_data/', area[i], '.json'))
}
servr::httd('~/working/bigmap')
cronR:::cron_rstudioaddin()
cronR:::cron_rstudioaddin()
cronR:::cron_rstudioaddin()
cronR:::cron_rstudioaddin()
#edit index files
index <- readLines('~/working/bigmap/index.html')
index
grep('last_date = ', index)
index[grep('last_date = ', index)]
index[grep('last_date = ', index)][2]
index[grep('last_date = ', index)][1]
index[grep('last_date = ', index)][2]
#edit index files
index <- readLines('~/working/bigmap/index.html')
index[grep('last_date = ', index)][2]
d <- index[grep('last_date = ', index)][2]
gsub('[0-9]{8}', 'test', d)
Sys.Date()
gsub(Sys.Date(), '-', '')
gsub('-', '', Sys.Date())
gsub('-', '', Sys.Date()) - 1
latest <- list.files('~/working/bigmap/geojsons/')
latest
latest <- latest[length(latest)]
latest
latest <- gsub('.geojson', '', latest)
latest
gsub('[0-9]{8}', latest, d)
d
d_new <- gsub('[0-9]{8}', latest, d)
grep('last_date = ', index)[2]
index[grep('last_date = ', index)[2]]
index[grep('last_date = ', index)[2]] <- d_new
writeLines(index, '~/working/bigmap/index.html')
writeLines(index, '~/working/bigmap_alt/index.html')
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
setwd('~/working/bigmap')
#check if need to update
main <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv', colClasses = 'character', showProgress = FALSE)
main <- main[countyFIPS != '0']
keep_cols <- grep('V',colnames(main), invert = TRUE)
main <- main[, keep_cols, with=FALSE]
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
facts_date
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
latest <- list.files('~/working/bigmap/geojsons/')
latest <- latest[length(latest)]
latest <- gsub('.geojson', '', latest)
map_date <- list.files('')
latest
map_date <- as.Date(latest, '%Y%m%d')
map_date
facts_date
#---finish cleaning up the usafacts data
colnames(main)
#---finish cleaning up the usafacts data
length(colnames(main))
main[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', main[nchar(countyFIPS) == 4, countyFIPS])
main[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', main[nchar(countyFIPS) == 4, countyFIPS])
df <- melt.data.table(main, id.vars = 1:4, measure.vars = 5:ncol(main), variable.name = 'date', value.name = 'case_count')
df[, date := as.Date(as.character(date), format = '%m/%d/%y')][
, case_count := as.integer(gsub(',', '', case_count))
]
df <- main[, c(1:4, ncol(main))]
df <- main[, c(1:4, ncol(main))]
main[, c(1:4, ncol(main))]
df <- main[, c(1:4, ncol(main)), with = FALSE]
colnames(df)[length(df)] <- 'case_count'
df[, delta := lapply(.SD, function(d) d - shift(d)), by = countyFIPS, .SDcols = 'case_count']
df[, case_count := as.numeric(case_count)]
df[, delta := lapply(.SD, function(d) d - shift(d)), by = countyFIPS, .SDcols = 'case_count']
#---finish cleaning up the usafacts data
main[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', main[nchar(countyFIPS) == 4, countyFIPS])
df <- melt.data.table(main, id.vars = 1:4, measure.vars = 5:ncol(main), variable.name = 'date', value.name = 'case_count')
df[, date := as.Date(as.character(date), format = '%m/%d/%y')][
, case_count := as.integer(gsub(',', '', case_count))
]
df[, date := as.Date(date)]
Sys.Date() - 8
df[date > Sys.Date() - 7]
df <- df[date > Sys.Date() - 7]
df[, delta := lapply(.SD, function(d) d - shift(d)), by = countyFIPS, .SDcols = 'case_count']
View(df)
df[, per_delta := lapply(.SD, function(d) (d - shift(d))/shift(d)), by = countyFIPS, .SDcols = 'case_count']
df[is.nan(per_delta), 'per_delta'] <- NA
df[is.infinite(per_delta), 'per_delta'] <- NA
df[, r_t := rt.func.v2(case_count), by = 'countyFIPS']
#functions used
rt.func.v2<-function(dat,mean.Weibull=4.8,sd.Weibull=2.3){
r.vals<-numeric(length = (length(dat) - 2))
mGT.params<-weibullpar(mean.Weibull, sd.Weibull, loc = 0)
alpha<-mGT.params[2]
beta<-mGT.params[1]
q<-exp(-as.numeric(alpha)^(-as.numeric(beta)))
w<- ddweibull(0:1000, as.numeric(q), as.numeric(beta), log = FALSE)
growth<-diff(dat)
growth<-pmax(growth, 0)
for(k in 2:length(growth)){
r.vals[k-1]<-growth[k]/(sum(growth[1:k]*rev(w[1:k])))
}
return(c(NA, NA, r.vals))
}
df[, r_t := rt.func.v2(case_count), by = 'countyFIPS']
deaths <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv',
colClasses = 'character', showProgress = FALSE)
df <- df[order(countyFIPS, date)]
df <- df[, r_t_three := frollmean(r_t, n = 3), by = countyFIPS]
df <- df[, r_t_seven := frollmean(r_t, n = 7), by = countyFIPS]
